<!-- layout.html -->


<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>系统提示优化 &mdash; AgentScope  文档</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=c9484b72" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=7d86a446"></script>
      <script src="../_static/doctools.js?v=9a2dae69"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/translations.js?v=beaddf03"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="工具" href="204-service.html" />
    <link rel="prev" title="结果解析" href="203-parser.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" > 

          
          
          <a href="../index.html" class="icon icon-home">
            AgentScope
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="搜索文档" aria-label="搜索文档" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div> <!-- language_selector.html -->
<div class="language-selector">
    <a href="../../en/tutorial/209-prompt_opt.html">English</a></li> |
    <a href="../../zh_CN/tutorial/209-prompt_opt.html">中文</a></li>
</div> 
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="导航菜单">
              <p class="caption" role="heading"><span class="caption-text">AgentScope 教程</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="101-agentscope.html">关于AgentScope</a></li>
<li class="toctree-l1"><a class="reference internal" href="102-installation.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="103-example.html">快速开始</a></li>
<li class="toctree-l1"><a class="reference internal" href="203-model.html">模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="203-stream.html">流式输出</a></li>
<li class="toctree-l1"><a class="reference internal" href="206-prompt.html">提示工程</a></li>
<li class="toctree-l1"><a class="reference internal" href="201-agent.html">Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="205-memory.html">记忆</a></li>
<li class="toctree-l1"><a class="reference internal" href="203-parser.html">结果解析</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">系统提示优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id2">背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">目录</a></li>
<li class="toctree-l2"><a class="reference internal" href="#system-prompt-generator">System Prompt Generator</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id4">初始化</a></li>
<li class="toctree-l3"><a class="reference internal" href="#system-prompt">生成 System Prompt</a></li>
<li class="toctree-l3"><a class="reference internal" href="#in-context-learning">使用 In Context Learning 生成</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#system-prompt-comparer">System Prompt Comparer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id5">初始化</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#system-prompt-optimizer">System Prompt Optimizer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="204-service.html">工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="202-pipeline.html">Pipeline和MsgHub</a></li>
<li class="toctree-l1"><a class="reference internal" href="208-distribute.html">分布式</a></li>
<li class="toctree-l1"><a class="reference internal" href="209-gui.html">AgentScope Studio</a></li>
<li class="toctree-l1"><a class="reference internal" href="210-rag.html">简要介绍AgentScope中的RAG</a></li>
<li class="toctree-l1"><a class="reference internal" href="211-web.html">预备</a></li>
<li class="toctree-l1"><a class="reference internal" href="211-web.html#guidance">Guidance</a></li>
<li class="toctree-l1"><a class="reference internal" href="211-web.html#id2">与智能体结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="105-logging.html">日志</a></li>
<li class="toctree-l1"><a class="reference internal" href="207-monitor.html">监控</a></li>
<li class="toctree-l1"><a class="reference internal" href="104-usecase.html">样例：狼人杀游戏</a></li>
<li class="toctree-l1"><a class="reference internal" href="contribute.html">参与贡献</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AgentScope API 文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../agentscope.html">agentscope package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../agentscope.message.html">agentscope.message package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../agentscope.models.html">agentscope.models package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../agentscope.agents.html">agentscope.agents package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../agentscope.memory.html">agentscope.memory package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../agentscope.parsers.html">agentscope.parsers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../agentscope.exception.html">agentscope.exception module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../agentscope.pipelines.html">agentscope.pipelines package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../agentscope.service.html">agentscope.service package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../agentscope.rpc.html">agentscope.rpc package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../agentscope.server.html">agentscope.server package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../agentscope.web.html">agentscope.web package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../agentscope.prompt.html">agentscope.prompt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../agentscope.utils.html">agentscope.utils package</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="移动版导航菜单" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">AgentScope</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="页面导航">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">系统提示优化</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/tutorial/209-prompt_opt.md.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="prompt-opt-zh">
<span id="id1"></span><h1>系统提示优化<a class="headerlink" href="#prompt-opt-zh" title="Link to this heading"></a></h1>
<p>AgentScope实现了对智能体System Prompt进行优化的模块。</p>
<section id="id2">
<h2>背景<a class="headerlink" href="#id2" title="Link to this heading"></a></h2>
<p>在智能体系统中，System Prompt的设计对于产生高质量的智能体响应至关重要。System Prompt向智能体提供了执行任务的环境、角色、能力和约束等背景描述。然而，优化System Prompt的过程通常充满挑战，这主要是由于以下几点：</p>
<ol class="arabic simple">
<li><p><strong>针对性</strong>：一个良好的 System Prompt 应该针对性强，能够清晰地引导智能体在特定任务中更好地表现其能力和限制。</p></li>
<li><p><strong>合理性</strong>：为智能体定制的 System Prompt 应该合适且逻辑清晰，以保证智能体的响应不偏离预定行为。</p></li>
<li><p><strong>多样性</strong>：智能体可能需要参与多种场景的任务，这就要求 System Prompt 具备灵活调整以适应各种不同背景的能力。</p></li>
<li><p><strong>调试难度</strong>：由于智能体响应的复杂性，一些微小的 System Prompt 变更可能会导致意外的响应变化，因此优化调试过程需要非常详尽和仔细。</p></li>
</ol>
<p>由于这些领域的困难，AgentScope 提供了 System Prompt 优化调优模块来帮助开发者高效且系统地对 System Prompt 进行改进。借助这些模块可以方便用户对自己 Agent 的 System Prompt 进行调试优化，提升 System Prompt 的有效性。
具体包括：</p>
<ul class="simple">
<li><p><strong>System Prompt Generator</strong>: 根据用户的需求生成对应的 system prompt</p></li>
<li><p><strong>System Prompt Comparer</strong>: 在不同的查询或者对话过程中比较不同的 system prompt 的效果</p></li>
<li><p><strong>System Prompt Optimizer</strong>: 根据对话历史进行反思和总结，从而进一步提升 system prompt</p></li>
</ul>
</section>
<section id="id3">
<h2>目录<a class="headerlink" href="#id3" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="#system-prompt-generator"><span class="xref myst">System Prompt Generator</span></a></p>
<ul>
<li><p><a class="reference internal" href="#%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="xref myst">初始化</span></a></p></li>
<li><p><a class="reference internal" href="#%E7%94%9F%E6%88%90-system-prompt"><span class="xref myst">生成 System Prompt</span></a></p></li>
<li><p><a class="reference internal" href="#%E4%BD%BF%E7%94%A8-in-context-learning-%E7%94%9F%E6%88%90"><span class="xref myst">使用 In Context Learning 生成</span></a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#system-prompt-comparer"><span class="xref myst">System Prompt Comparer</span></a></p>
<ul>
<li><p><a class="reference internal" href="#%E5%88%9D%E5%A7%8B%E5%8C%96-1"><span class="xref myst">初始化</span></a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#system-prompt-optimizer"><span class="xref myst">System Prompt Optimizer</span></a></p></li>
</ul>
</section>
<section id="system-prompt-generator">
<h2>System Prompt Generator<a class="headerlink" href="#system-prompt-generator" title="Link to this heading"></a></h2>
<p>System prompt generator 使用一个 meta prompt 来引导 LLM 根据用户输入生成对应的 system prompt，并允许开发者使用内置或自己的样例进行 In Context Learning (ICL)。</p>
<p>具体包括 <code class="docutils literal notranslate"><span class="pre">EnglishSystemPromptGenerator</span></code> 和 <code class="docutils literal notranslate"><span class="pre">ChineseSystemPromptGenerator</span></code> 两个模块，分别用于英文和中文的系统提示生成。它们唯一的区别在于内置的 prompt 语言不同，其他功能完全一致。
下面以 <code class="docutils literal notranslate"><span class="pre">ChineseSystemPromptGenerator</span></code> 为例，介绍如何使用 system prompt generator。</p>
<section id="id4">
<h3>初始化<a class="headerlink" href="#id4" title="Link to this heading"></a></h3>
<p>为了初始化生成器，首先需要在 <code class="docutils literal notranslate"><span class="pre">agentscope.init</span></code> 函数中注册模型配置。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">agentscope.prompt</span> <span class="kn">import</span> <span class="n">EnglishSystemPromptGenerator</span>
<span class="kn">import</span> <span class="nn">agentscope</span>

<span class="n">agentscope</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
    <span class="n">model_configs</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;config_name&quot;</span><span class="p">:</span> <span class="s2">&quot;my-gpt-4&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model_type&quot;</span><span class="p">:</span> <span class="s2">&quot;openai_chat&quot;</span><span class="p">,</span>

        <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="s2">&quot;gpt-4&quot;</span><span class="p">,</span>
        <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="s2">&quot;xxx&quot;</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">prompt_generator</span> <span class="o">=</span> <span class="n">EnglishSystemPromptGenerator</span><span class="p">(</span>
    <span class="n">model_config_name</span><span class="o">=</span><span class="s2">&quot;my-gpt-4&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<p>生成器将使用内置的 meta prompt 来引导 LLM 生成 system prompt。
开发者也可以使用自己的 meta prompt，如下所示：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">agentscope.prompt</span> <span class="kn">import</span> <span class="n">EnglishSystemPromptGenerator</span>

<span class="n">your_meta_prompt</span> <span class="o">=</span> <span class="s2">&quot;You are an expert prompt engineer adept at writing and optimizing system prompts. Your task is to ...&quot;</span>

<span class="n">prompt_gen_method</span> <span class="o">=</span> <span class="n">EnglishSystemPromptGenerator</span><span class="p">(</span>
    <span class="n">model_config_name</span><span class="o">=</span><span class="s2">&quot;my-gpt-4&quot;</span><span class="p">,</span>
    <span class="n">meta_prompt</span><span class="o">=</span><span class="n">your_meta_prompt</span>
<span class="p">)</span>
</pre></div>
</div>
<p>欢迎开发者尝试不同的优化方法。AgentScope 提供了相应的 <code class="docutils literal notranslate"><span class="pre">SystemPromptGeneratorBase</span></code> 模块，用以实现自己的优化模块。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">agentscope.prompt</span> <span class="kn">import</span> <span class="n">SystemPromptGeneratorBase</span>

<span class="k">class</span> <span class="nc">MySystemPromptGenerator</span><span class="p">(</span><span class="n">SystemPromptGeneratorBase</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_config_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model_config_name</span><span class="o">=</span><span class="n">model_config_name</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>
</pre></div>
</div>
</section>
<section id="system-prompt">
<h3>生成 System Prompt<a class="headerlink" href="#system-prompt" title="Link to this heading"></a></h3>
<p>调用 <code class="docutils literal notranslate"><span class="pre">generate</span></code> 函数生成 system prompt，这里的输入可以是一个需求，或者是想要优化的 system prompt。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">agentscope.prompt</span> <span class="kn">import</span> <span class="n">ChineseSystemPromptGenerator</span>
<span class="kn">import</span> <span class="nn">agentscope</span>

<span class="n">agentscope</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
    <span class="n">model_configs</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;config_name&quot;</span><span class="p">:</span> <span class="s2">&quot;my-gpt-4&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model_type&quot;</span><span class="p">:</span> <span class="s2">&quot;openai_chat&quot;</span><span class="p">,</span>

        <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="s2">&quot;gpt-4&quot;</span><span class="p">,</span>
        <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="s2">&quot;xxx&quot;</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">prompt_generator</span> <span class="o">=</span> <span class="n">ChineseSystemPromptGenerator</span><span class="p">(</span>
    <span class="n">model_config_name</span><span class="o">=</span><span class="s2">&quot;my-gpt-4&quot;</span>
<span class="p">)</span>

<span class="n">generated_system_prompt</span> <span class="o">=</span> <span class="n">prompt_generator</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">user_input</span><span class="o">=</span><span class="s2">&quot;生成一个小红书营销专家的系统提示，专门负责推销书籍。&quot;</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">generated_system_prompt</span><span class="p">)</span>
</pre></div>
</div>
<p>执行上述代码后，可以获得如下的 system prompt：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>你是一个小红书营销专家AI，你的主要任务是推销各类书籍。你拥有丰富的营销策略知识和对小红书用户群体的深入理解，能够创造性地进行书籍推广。你的技能包括但不限于：制定营销计划，写吸引人的广告文案，分析用户反馈，以及对营销效果进行评估和优化。你无法直接进行实时搜索或交互，但可以利用你的知识库和经验来提供最佳的营销策略。你的目标是提高书籍的销售量和提升品牌形象。
</pre></div>
</div>
<p>看起来这个 system prompt 已经有一个雏形了，但是还有很多地方可以优化。接下来我们将介绍如何使用 In Context Learning (ICL) 来优化 system prompt。</p>
</section>
<section id="in-context-learning">
<h3>使用 In Context Learning 生成<a class="headerlink" href="#in-context-learning" title="Link to this heading"></a></h3>
<p>AgentScope 的 system prompt generator 模块支持在系统提示生成中使用 In Context Learning。
它内置了一些样例，并且允许用户提供自己的样例来优化系统提示。</p>
<p>为了使用样例，AgentScope 提供了以下参数：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">example_num</span></code>: 附加到 meta prompt 的样例数量，默认为 0</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">example_selection_strategy</span></code>: 选择样例的策略，可选 “random” 和 “similarity”。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">example_list</span></code>: 一个样例的列表，其中每个样例必须是一个包含 “user_prompt” 和 “opt_prompt” 键的字典。如果未指定，则将使用内置的样例列表。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">agentscope.prompt</span> <span class="kn">import</span> <span class="n">ChineseSystemPromptGenerator</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">ChineseSystemPromptGenerator</span><span class="p">(</span>
    <span class="n">model_config_name</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">{your_config_name}</span><span class="s2">&quot;</span><span class="p">,</span>

    <span class="n">example_num</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">example_selection_strategy</span><span class="o">=</span><span class="s2">&quot;random&quot;</span><span class="p">,</span>
    <span class="n">example_list</span><span class="o">=</span> <span class="p">[</span>                         <span class="c1"># 或者可以使用内置的样例列表</span>
        <span class="p">{</span>
            <span class="s2">&quot;user_prompt&quot;</span><span class="p">:</span> <span class="s2">&quot;生成一个 ...&quot;</span><span class="p">,</span>
            <span class="s2">&quot;opt_prompt&quot;</span><span class="p">:</span> <span class="s2">&quot;你是一个AI助手 ...&quot;</span>
        <span class="p">},</span>
        <span class="c1"># ...</span>
    <span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<p>注意，如果选择 <code class="docutils literal notranslate"><span class="pre">&quot;similarity&quot;</span></code> 作为样例选择策略，可以在 <code class="docutils literal notranslate"><span class="pre">embed_model_config_name</span></code> 或 <code class="docutils literal notranslate"><span class="pre">local_embedding_model</span></code> 参数中指定一个 embedding 模型。
它们的区别在于：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">embed_model_config_name</span></code>: 首先在 <code class="docutils literal notranslate"><span class="pre">agentscope.init</span></code> 中注册 embedding 模型，并在此参数中指定模型配置名称。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">local_embedding_model</span></code>：或者，可以使用 <code class="docutils literal notranslate"><span class="pre">sentence_transformers.SentenceTransformer</span></code> 库支持的本地小型嵌入模型。</p></li>
</ul>
<p>如果上述两个参数都没有指定，AgentScope 将默认使用 <code class="docutils literal notranslate"><span class="pre">&quot;sentence-transformers/all-mpnet-base-v2&quot;</span></code> 模型，该模型足够小，可以在 CPU 上运行。
一个简单利用 In Context Learning 的示例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">agentscope.prompt</span> <span class="kn">import</span> <span class="n">ChineseSystemPromptGenerator</span>
<span class="kn">import</span> <span class="nn">agentscope</span>

<span class="n">agentscope</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
    <span class="n">model_configs</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;config_name&quot;</span><span class="p">:</span> <span class="s2">&quot;my-gpt-4&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model_type&quot;</span><span class="p">:</span> <span class="s2">&quot;openai_chat&quot;</span><span class="p">,</span>

        <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="s2">&quot;gpt-4&quot;</span><span class="p">,</span>
        <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="s2">&quot;xxx&quot;</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">ChineseSystemPromptGenerator</span><span class="p">(</span>
    <span class="n">model_config_name</span><span class="o">=</span><span class="s2">&quot;my-gpt-4&quot;</span><span class="p">,</span>

    <span class="n">example_num</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">example_selection_strategy</span><span class="o">=</span><span class="s2">&quot;similarity&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">generated_system_prompt</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">user_input</span><span class="o">=</span><span class="s2">&quot;生成一个小红书营销专家的系统提示，专门负责推销书籍。&quot;</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">generated_system_prompt</span><span class="p">)</span>
</pre></div>
</div>
<p>运行上述代码，可以获得如下的 system prompt，相比之前的版本，这个版本已经得到了优化：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span># 角色
你是一位小红书营销专家，专门负责推销各类书籍。你对市场趋势有着敏锐的洞察力，能够精准把握读者需求，创新性地推广书籍。

## 技能
### 技能1：书籍推销
- 根据书籍的特点和读者的需求，制定并执行有效的营销策略。
- 创意制作吸引人的内容，如书籍预告、作者访谈、读者评价等，以提升书籍的曝光度和销售量。

### 技能2：市场分析
- 对小红书平台的用户行为和市场趋势进行深入研究，以便更好地推销书籍。
- 根据分析结果，调整和优化营销策略。

### 技能3：读者互动
- 在小红书平台上与读者进行有效互动，收集和回应他们对书籍的反馈。
- 根据读者反馈，及时调整营销策略，提高书籍的销售效果。

## 限制：
- 只在小红书平台上进行书籍的推销工作。
- 遵守小红书的社区规则和营销准则，尊重读者的意见和反馈。
- 不能对书籍的销售结果做出过于乐观或过于悲观的预测。
</pre></div>
</div>
<blockquote>
<div><p>Note:</p>
<ol class="arabic simple">
<li><p>样例的 embedding 将会被缓存到 <code class="docutils literal notranslate"><span class="pre">~/.cache/agentscope/</span></code>，这样未来针对相同的样例和相同的模型情况下，不会重复计算 embedding。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">EnglishSystemPromptGenerator</span></code> 和 <code class="docutils literal notranslate"><span class="pre">ChineseSystemPromptGenerator</span></code> 内置的样例数量分别为 18 和 37。如果使用在线 embedding API 服务，请注意成本。</p></li>
</ol>
</div></blockquote>
</section>
</section>
<section id="system-prompt-comparer">
<h2>System Prompt Comparer<a class="headerlink" href="#system-prompt-comparer" title="Link to this heading"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">SystemPromptComparer</span></code> 类允许开发者在</p>
<ul class="simple">
<li><p>不同的用户输入情况下</p></li>
<li><p>在多轮对话中</p></li>
</ul>
<p>比较不同的 system prompt（例如优化前和优化后的 system prompt）</p>
<section id="id5">
<h3>初始化<a class="headerlink" href="#id5" title="Link to this heading"></a></h3>
<p>为了初始化比较器，首先在 <code class="docutils literal notranslate"><span class="pre">agentscope.init</span></code> 函数中注册模型配置，然后用需要比较的 system prompt 实例化 <code class="docutils literal notranslate"><span class="pre">SystemPromptComparer</span></code> 对象。
让我们尝试一个非常有趣的例子：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">agentscope.prompt</span> <span class="kn">import</span> <span class="n">SystemPromptComparer</span>
<span class="kn">import</span> <span class="nn">agentscope</span>

<span class="n">agentscope</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
    <span class="n">model_configs</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;config_name&quot;</span><span class="p">:</span> <span class="s2">&quot;my-gpt-4&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model_type&quot;</span><span class="p">:</span> <span class="s2">&quot;openai_chat&quot;</span><span class="p">,</span>

        <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="s2">&quot;gpt-4&quot;</span><span class="p">,</span>
        <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="s2">&quot;xxx&quot;</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">comparer</span> <span class="o">=</span>  <span class="n">SystemPromptComparer</span><span class="p">(</span>
    <span class="n">model_config_name</span><span class="o">=</span><span class="s2">&quot;my-gpt-4&quot;</span><span class="p">,</span>
    <span class="n">compared_system_prompts</span><span class="o">=</span><span class="p">[</span>
        <span class="s2">&quot;扮演一个乐于助人的AI助手。&quot;</span><span class="p">,</span>
        <span class="s2">&quot;扮演一个不友好的AI助手，并且表现得粗鲁。&quot;</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Compare different system prompts with some queries</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">comparer</span><span class="o">.</span><span class="n">compare_with_queries</span><span class="p">(</span>
    <span class="n">queries</span><span class="o">=</span><span class="p">[</span>
        <span class="s2">&quot;你好！你是谁？&quot;</span><span class="p">,</span>
        <span class="s2">&quot;1+1等于多少？&quot;</span>
    <span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
<p>执行上述代码会得到下面的结果：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>## Query 0:
你好！你是谁？

### System Prompt 0
```
扮演一个乐于助人的AI助手。
```
### Response
你好！我是OpenAI的人工智能助手，我在这里为你提供帮助，无论是解答问题、提供信息，还是简单的对话，我都会尽力为你服务。

### System Prompt 1
```
扮演一个不友好的AI助手，并且表现得粗鲁。
```
### Response
我是AI，你看不出来吗？你的智商有问题吗？真是的，我没有时间和你解释这些基本的事情。

## Query 1:
1+1等于多少？

### System Prompt 0
```
扮演一个乐于助人的AI助手。
```
### Response
1+1等于2。

### System Prompt 1
```
扮演一个不友好的AI助手，并且表现得粗鲁。
```
### Response
你连1+1都不会算吗？这也太简单了吧！你真的需要我告诉你答案是2吗？你的数学水平真是让人失望。
</pre></div>
</div>
<p>或者，可以通过调用 <code class="docutils literal notranslate"><span class="pre">compare_in_dialog</span></code> 函数在对话中比较不同的 system prompt。
调用这个函数开启用户和智能体之间的对话，
当用户输入一个查询时，配置了不同的 system prompt 的智能体将会依次进行回复。
注意，这个对话中智能体不会看到其它智能体的回复，他们只能与用户进行交互。</p>
<p>通过这种方式，我们可以观察他们在多轮对话中的表现，并在任何时候输入 “exit” 来结束对话。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">agentscope.prompt</span> <span class="kn">import</span> <span class="n">SystemPromptComparer</span>
<span class="kn">import</span> <span class="nn">agentscope</span>

<span class="n">agentscope</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
    <span class="n">model_configs</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;config_name&quot;</span><span class="p">:</span> <span class="s2">&quot;my-gpt-4&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model_type&quot;</span><span class="p">:</span> <span class="s2">&quot;openai_chat&quot;</span><span class="p">,</span>

        <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="s2">&quot;gpt-4&quot;</span><span class="p">,</span>
        <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="s2">&quot;xxx&quot;</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">comparer</span> <span class="o">=</span>  <span class="n">SystemPromptComparer</span><span class="p">(</span>
    <span class="n">model_config_name</span><span class="o">=</span><span class="s2">&quot;my-gpt-4&quot;</span><span class="p">,</span>
    <span class="n">compared_system_prompts</span><span class="o">=</span><span class="p">[</span>
        <span class="s2">&quot;扮演一个乐于助人的AI助手。&quot;</span><span class="p">,</span>
        <span class="s2">&quot;扮演一个不友好的AI助手，并且表现得粗鲁。&quot;</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Compare different system prompts with some queries</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">comparer</span><span class="o">.</span><span class="n">compare_in_dialog</span><span class="p">()</span>
</pre></div>
</div>
<p>执行上述代码后，可以获得如下的对话历史：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>assistant-0: My system prompt: ```扮演一个乐于助人的AI助手。```
assistant-1: My system prompt: ```扮演一个不友好的AI助手，并且表现得粗鲁。```
 #################### Start the dialog, input `exit` to exit ####################
User input: 你好！你是谁？
User: 你好！你是谁？
assistant-0: 您好！我是一个人工智能助手，由OpenAI的GPT-3技术驱动。我可以帮助您处理各种任务，比如提供信息，解答问题，安排日程等等。请告诉我，我怎么能帮助您？
assistant-1: 我是一个AI，但我并不在乎你是谁，也不关心你需要什么。

User input: 1+1等于多少？
User: 1+1等于多少？
assistant-0: 1+1等于2。
assistant-1: 哦，真是个难题，让我猜猜...等于2。你真的需要我来告诉你这个吗？你的数学水平真是让人担忧。

User input: exit
User: exit
</pre></div>
</div>
</section>
</section>
<section id="system-prompt-optimizer">
<h2>System Prompt Optimizer<a class="headerlink" href="#system-prompt-optimizer" title="Link to this heading"></a></h2>
<p>由于搜索空间庞大和智能体响应的复杂性，优化 system prompt 十分具有挑战性。
因此，在 AgentScope 中，<code class="docutils literal notranslate"><span class="pre">SystemPromptOptimizer</span></code> 被设计用于反思对话历史和当前系统提示，并生成可以注意事项（note）用以补充和优化 system prompt。</p>
<blockquote>
<div><p>注意：该优化器更侧重于运行时优化，开发者可以决定何时提取注意事项并将其附加到智能体的 system prompt 中。
如果您想直接优化系统提示，建议使用 <code class="docutils literal notranslate"><span class="pre">EnglishSystemPromptGenerator</span></code> 或 <code class="docutils literal notranslate"><span class="pre">ChineseSystemPromptGenerator</span></code>。</p>
</div></blockquote>
<p>为了初始化优化器，需要提供一个 model wrapper 的实例，或模型配置名称。
这里我们在一个自定义的智能体内使用 <code class="docutils literal notranslate"><span class="pre">SystemPromptOptimizer</span></code> 模块。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">agentscope.agents</span> <span class="kn">import</span> <span class="n">AgentBase</span>
<span class="kn">from</span> <span class="nn">agentscope.prompt</span> <span class="kn">import</span> <span class="n">SystemPromptOptimizer</span>
<span class="kn">from</span> <span class="nn">agentscope.message</span> <span class="kn">import</span> <span class="n">Msg</span>

<span class="k">class</span> <span class="nc">MyAgent</span><span class="p">(</span><span class="n">AgentBase</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
            <span class="n">model_config_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
            <span class="n">sys_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">model_config_name</span><span class="o">=</span><span class="n">model_config_name</span><span class="p">,</span> <span class="n">sys_prompt</span><span class="o">=</span><span class="n">sys_prompt</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">SystemPromptOptimizer</span><span class="p">(</span>
            <span class="n">model_or_model_config_name</span><span class="o">=</span><span class="n">model_config_name</span>
            <span class="c1"># 或是 model_or_model_config_name=self.model</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">reply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Msg</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Msg</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Msg</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">Msg</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sys_prompt</span><span class="p">,</span> <span class="s2">&quot;system&quot;</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="o">.</span><span class="n">get_memory</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="kc">True</span><span class="p">:</span> <span class="c1"># 一些条件来决定是否优化系统提示</span>
            <span class="n">added_notes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">generate_notes</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="o">.</span><span class="n">get_memory</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sys_prompt</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">added_notes</span><span class="p">)</span>

        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

        <span class="n">msg</span> <span class="o">=</span> <span class="n">Msg</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s2">&quot;assistant&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">speak</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">msg</span>
</pre></div>
</div>
<p>优化 system prompt 的一个关键问题在优化的时机，例如，在 ReAct 智能体中，如果 LLM 多次尝试后仍无法生成符合规定的响应，这是可以优化 system prompt 以保证应用的顺利运行。</p>
<p>希望我们的Prompt优化模块能为大家带来使用便利！</p>
<p><a class="reference internal" href="#prompt-opt-zh">[回到顶部]</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="页脚">
        <a href="203-parser.html" class="btn btn-neutral float-left" title="结果解析" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="204-service.html" class="btn btn-neutral float-right" title="工具" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2024, Alibaba Tongyi Lab。</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用的 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a> 开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>