{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# \u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\n\nAgentscope \u5185\u7f6e\u4e86\u5bf9\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u652f\u6301\u3002AgentScope \u4e2d\u4e0e RAG \u76f8\u5173\u7684\u4e24\u4e2a\u5173\u952e\u6a21\u5757\u662f\uff1aKnowledge \u548c KnowledgeBank\u3002\n\n## \u521b\u5efa\u548c\u4f7f\u7528\u77e5\u8bc6(Knowledge)\u5b9e\u4f8b\n\n\u867d\u7136 Knowledge \u662f\u4e00\u4e2a\u57fa\u7c7b\uff0c\u4f46 AgentScope \u4e2d\u76ee\u524d\u6709\u4e00\u4e2a\u5177\u4f53\u7684\u5185\u7f6e\u77e5\u8bc6\u7c7b\u3002\uff08\u5728\u7ebf\u641c\u7d22\u4f1a\u77e5\u8bc6\u7c7b\u4f1a\u5f88\u5feb\u66f4\u65b0\u3002\uff09\n\n- LlamaIndexKnowledge\uff1a\u65e8\u5728\u4e0e\u6700\u6d41\u884c\u7684 RAG \u5e93\u4e4b\u4e00 [LlamaIndex](https://www.llamaindex.ai/) \u534f\u540c\u5de5\u4f5c\uff0c\u7528\u4f5c\u672c\u5730\u77e5\u8bc6\uff0c\u5e76\u901a\u8fc7\u914d\u7f6e\u652f\u6301 LlamaIndex \u7684\u5927\u90e8\u5206\u529f\u80fd\u3002\n\n\n### \u521b\u5efa\u4e00\u4e2a LlamaIndexKnowledge \u5b9e\u4f8b\n\n\u5feb\u901f\u521b\u5efa\u4e00\u4e2a LlamaIndexKnowledge \u5b9e\u4f8b\u7684\u65b9\u6cd5\u662f\u4f7f\u7528 build_knowledge_instance \u51fd\u6570\u3002\n\u8be5\u51fd\u6570\u9700\u8981\u4f20\u5165\u4e09\u4e2a\u53c2\u6570\uff1a\n\nknowledge_id\uff1a\u8be5\u77e5\u8bc6\u5b9e\u4f8b\u7684\u552f\u4e00\u6807\u8bc6\u7b26\n\ndata_dirs_and_types\uff1a\u4e00\u4e2a\u5b57\u5178\uff0c\u5176\u952e\u4e3a\u6570\u636e\u6240\u5728\u76ee\u5f55\u7684\u5b57\u7b26\u4e32\uff0c\u503c\u4e3a\u6570\u636e\u6587\u4ef6\u7684\u6269\u5c55\u540d\n\nemb_model_config_name\uff1aAgentScope \u4e2dembedding\u6a21\u578b\u914d\u7f6e\u7684\u540d\u79f0\uff08\u9700\u8981\u5728 AgentScope \u4e2d\u9884\u5148\u521d\u59cb\u5316\uff09\n\n\u4e00\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\u5982\u4e0b\u3002\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport agentscope\nfrom agentscope.rag.llama_index_knowledge import LlamaIndexKnowledge\n\nagentscope.init(\n    model_configs=[\n        {\n            \"model_type\": \"dashscope_text_embedding\",\n            \"config_name\": \"qwen_emb_config\",\n            \"model_name\": \"text-embedding-v2\",\n            \"api_key\": os.getenv(\"DASHSCOPE_API_KEY\"),\n        },\n    ],\n)\n\nlocal_knowledge = LlamaIndexKnowledge.build_knowledge_instance(\n    knowledge_id=\"agentscope_qa\",\n    data_dirs_and_types={\"./\": [\".md\"]},\n    emb_model_config_name=\"qwen_emb_config\",\n)\n\n\nnodes = local_knowledge.retrieve(\n    \"what is agentscope?\",\n    similarity_top_k=1,\n)\n\nprint(f\"\\nThe retrieved content:\\n{nodes[0].content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5982\u679c\u5e0c\u671b\u5bf9\u6570\u636e\u7684\u9884\u5904\u7406\u6709\u66f4\u591a\u7684\u63a7\u5236\uff0c\n\u53ef\u4ee5\u5c06\u4e00\u4e2a\u77e5\u8bc6\u914d\u7f6e\u4f20\u9012\u7ed9\u8be5\u51fd\u6570\u3002\n\u7279\u522b\u5730\uff0c`SimpleDirectoryReader` \u662f LlamaIndex \u5e93\u4e2d\u7684\u4e00\u4e2a\u7c7b\uff0c\u800c `init_args` \u662f `SimpleDirectoryReader` \u7684\u521d\u59cb\u5316\u53c2\u6570\u3002\n\u81f3\u4e8e\u6570\u636e\u9884\u5904\u7406\uff0c\u5f00\u53d1\u8005\u53ef\u4ee5\u9009\u62e9\u4e0d\u540c\u7684 LlamaIndex [transformation operations](https://docs.llamaindex.ai/en/stable/module_guides/loading/ingestion_pipeline/transformations/) \u6765\u5bf9\u6570\u636e\u8fdb\u884c\u9884\u5904\u7406\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "flex_knowledge_config = {\n    \"knowledge_id\": \"agentscope_qa_flex\",\n    \"knowledge_type\": \"llamaindex_knowledge\",\n    \"emb_model_config_name\": \"qwen_emb_config\",\n    \"chunk_size\": 1024,\n    \"chunk_overlap\": 40,\n    \"data_processing\": [\n        {\n            \"load_data\": {\n                \"loader\": {\n                    \"create_object\": True,\n                    \"module\": \"llama_index.core\",\n                    \"class\": \"SimpleDirectoryReader\",\n                    \"init_args\": {\n                        \"input_dir\": \"./\",\n                        \"required_exts\": [\n                            \".md\",\n                        ],\n                    },\n                },\n            },\n            \"store_and_index\": {\n                \"transformations\": [\n                    {\n                        \"create_object\": True,\n                        \"module\": \"llama_index.core.node_parser\",\n                        \"class\": \"SentenceSplitter\",\n                        \"init_args\": {\n                            \"chunk_size\": 1024,\n                        },\n                    },\n                ],\n            },\n        },\n    ],\n}\n\nlocal_knowledge_flex = LlamaIndexKnowledge.build_knowledge_instance(\n    knowledge_id=\"agentscope_qa_flex\",\n    knowledge_config=flex_knowledge_config,\n)\n\n\nnodes = local_knowledge.retrieve(\n    \"what is agentscope?\",\n    similarity_top_k=1,\n)\n\nprint(f\"\\nThe retrieved content:\\n{nodes[0].content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a Batch of Knowledge Instances\nFor some cases where different knowledge sources exists and require different preprocessing and/or post-process, a good strategy is to create multiple knowledge instances.\nThus, we introduce `KnowledgeBank` to better manage the knowledge instances. One can initialize a batch of knowledge with a file of multiple knowledge configurations.\n\n```python\nknowledge_bank = KnowledgeBank(configs=path_to_knowledge_configs_json)\n```\n\u6216\u8005\uff0c\u4e5f\u53ef\u4ee5\u5c06\u77e5\u8bc6\u5b9e\u4f8b\u52a8\u6001\u5730\u6dfb\u52a0\u5230\u77e5\u8bc6\u5e93\u4e2d\u3002\n\n```python\nknowledge_bank.add_data_as_knowledge(\n     knowledge_id=\"agentscope_tutorial_rag\",\n     emb_model_name=\"qwen_emb_config\",\n     data_dirs_and_types={\n         \"../../docs/sphinx_doc/en/source/tutorial\": [\".md\"],\n     },\n )\n```\n\u8fd9\u91cc\uff0c`knowledge_id` \u5e94\u8be5\u662f\u552f\u4e00\u7684\u3002\n\u5982\u679c\u5f00\u53d1\u8005\u6709\u4ed6\u4eec\u81ea\u5df1\u7684\u65b0\u77e5\u8bc6\u7c7b\uff0c\u53ef\u4ee5\u9884\u5148\u6ce8\u518c\u8be5\u65b0\u7c7b\u3002\n\n```python\nfrom your_knowledge import NewKnowledgeClass1, NewKnowledgeClass2\nknowledge_bank = KnowledgeBank(\n  configs=\"configs/knowledge_config.json\",\n  new_knowledge_types=[NewKnowledgeClass1, NewKnowledgeClass2]\n)\n# or\nknowledge_bank.register_knowledge_type(NewKnowledgeClass2)\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (\u62d3\u5c55) \u67b6\u8bbe\u81ea\u5df1\u7684embedding model\u670d\u52a1\n\n\u6211\u4eec\u5728\u6b64\u4e5f\u5bf9\u67b6\u8bbe\u672c\u5730embedding model\u611f\u5174\u8da3\u7684\u7528\u6237\u63d0\u4f9b\u4ee5\u4e0b\u7684\u6837\u4f8b\u3002\n\u4ee5\u4e0b\u6837\u4f8b\u57fa\u4e8e\u5728embedding model\u8303\u56f4\u4e2d\u5f88\u53d7\u6b22\u8fce\u7684`sentence_transformers` \u5305\uff08\u57fa\u4e8e`transformer` \u800c\u4e14\u517c\u5bb9HuggingFace\u548cModelScope\u7684\u6a21\u578b\uff09\u3002\n\u8fd9\u4e2a\u6837\u4f8b\u4e2d\uff0c\u6211\u4eec\u4f1a\u4f7f\u7528\u5f53\u4e0b\u6700\u597d\u7684\u6587\u672c\u5411\u91cf\u6a21\u578b\u4e4b\u4e00`gte-Qwen2-7B-instruct`\u3002\n\n* \u7b2c\u4e00\u6b65: \u9075\u5faa\u5728 [HuggingFace](https://huggingface.co/Alibaba-NLP/gte-Qwen2-7B-instruct) \u6216\u8005 [ModelScope](https://www.modelscope.cn/models/iic/gte_Qwen2-7B-instruct )\u7684\u6307\u793a\u4e0b\u8f7d\u6a21\u578b\u3002\n  (\u5982\u679c\u65e0\u6cd5\u76f4\u63a5\u4eceHuggingFace\u4e0b\u8f7d\u6a21\u578b\uff0c\u4e5f\u53ef\u4ee5\u8003\u8651\u4f7f\u7528HuggingFace\u955c\u50cf\uff1abash\u547d\u4ee4\u884c`export HF_ENDPOINT=https://hf-mirror.com`\uff0c\u6216\u8005\u5728Python\u4ee3\u7801\u4e2d\u52a0\u5165`os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"`)\n* \u7b2c\u4e8c\u6b65: \u8bbe\u7f6e\u670d\u52a1\u5668\u3002\u4ee5\u4e0b\u662f\u4e00\u6bb5\u53c2\u8003\u4ee3\u7801\u3002\n\n```python\nimport datetime\nimport argparse\n\nfrom flask import Flask\nfrom flask import request\nfrom sentence_transformers import SentenceTransformer\n\ndef create_timestamp(format_: str = \"%Y-%m-%d %H:%M:%S\") -> str:\n    \"\"\"Get current timestamp.\"\"\"\n    return datetime.datetime.now().strftime(format_)\n\napp = Flask(__name__)\n\n@app.route(\"/embedding/\", methods=[\"POST\"])\ndef get_embedding() -> dict:\n    \"\"\"Receive post request and return response\"\"\"\n    json = request.get_json()\n\n    inputs = json.pop(\"inputs\")\n\n    global model\n\n    if isinstance(inputs, str):\n        inputs = [inputs]\n\n    embeddings = model.encode(inputs)\n\n    return {\n        \"data\": {\n            \"completion_tokens\": 0,\n            \"messages\": {},\n            \"prompt_tokens\": 0,\n            \"response\": {\n                \"data\": [\n                    {\n                        \"embedding\": emb.astype(float).tolist(),\n                    }\n                    for emb in embeddings\n                ],\n                \"created\": \"\",\n                \"id\": create_timestamp(),\n                \"model\": \"flask_model\",\n                \"object\": \"text_completion\",\n                \"usage\": {\n                    \"completion_tokens\": 0,\n                    \"prompt_tokens\": 0,\n                    \"total_tokens\": 0,\n                },\n            },\n            \"total_tokens\": 0,\n            \"username\": \"\",\n        },\n    }\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model_name_or_path\", type=str, required=True)\n    parser.add_argument(\"--device\", type=str, default=\"auto\")\n    parser.add_argument(\"--port\", type=int, default=8000)\n    args = parser.parse_args()\n\n    global model\n\n    print(\"setting up for embedding model....\")\n    model = SentenceTransformer(\n        args.model_name_or_path\n    )\n\n    app.run(port=args.port)\n```\n* \u7b2c\u4e09\u90e8\uff1a\u542f\u52a8\u670d\u52a1\u5668\u3002\n\n```bash\npython setup_ms_service.py --model_name_or_path {$PATH_TO_gte_Qwen2_7B_instruct}\n```\n\u6d4b\u8bd5\u670d\u52a1\u662f\u5426\u6210\u529f\u542f\u52a8\u3002\n\n```python\nfrom agentscope.models.post_model import PostAPIEmbeddingWrapper\n\n\nmodel = PostAPIEmbeddingWrapper(\n    config_name=\"test_config\",\n    api_url=\"http://127.0.0.1:8000/embedding/\",\n    json_args={\n        \"max_length\": 4096,\n        \"temperature\": 0.5\n    }\n)\n\nprint(model(\"testing\"))\n```\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}