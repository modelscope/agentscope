{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# \u6a21\u578b API\n\nAgentScope \u5df2\u96c6\u6210\u4e86\u8bb8\u591a\u4e0d\u540c\u6a21\u6001\u7684\u6a21\u578b API \u3002\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>1. \u672c\u5217\u8868\u4e0d\u5305\u62ec\u6587\u672c\u5230\u8bed\u97f3(TTS)\u548c\u8bed\u97f3\u5230\u6587\u672c(STT)API\u3002\u60a8\u53ef\u4ee5\u53c2\u8003 `tools` \u4e00\u8282\u3002</p></div>\n 2. \u672c\u8282\u4ec5\u4ecb\u7ecd\u5982\u4f55\u5728AgentScope\u4e2d\u4f7f\u7528\u6216\u96c6\u6210\u4e0d\u540c\u7684\u6a21\u578bAPI\u3002\u5173\u4e8e\u63d0\u793a\u8981\u6c42\u548c\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\u7684\u5185\u5bb9\u5c06\u5728 `prompt-engineering` \u4e00\u8282\u4e2d\u4ecb\u7ecd\u3002\n\n\n.. list-table::\n    :header-rows: 1\n\n    * - API\n      - \u5bf9\u8bdd\n      - \u6587\u672c\u751f\u6210\n      - \u89c6\u89c9\n      - Embedding\n    * - OpenAI\n      - \u2713\n      - \u2717\n      - \u2713\n      - \u2713\n    * - DashScope\n      - \u2713\n      - \u2717\n      - \u2713\n      - \u2713\n    * - Gemini\n      - \u2713\n      - \u2717\n      - \u2717\n      - \u2713\n    * - Ollama\n      - \u2713\n      - \u2713\n      - \u2713\n      - \u2713\n    * - Yi\n      - \u2713\n      - \u2717\n      - \u2717\n      - \u2717\n    * - LiteLLM\n      - \u2713\n      - \u2717\n      - \u2717\n      - \u2717\n    * - ZhipuAI\n      - \u2713\n      - \u2717\n      - \u2717\n      - \u2713\n    * - Anthropic\n      - \u2713\n      - \u2717\n      - \u2717\n      - \u2717\n\n\u5728 AgentScope \u4e2d\u4f7f\u7528\u6a21\u578b API \u6709\u4e24\u79cd\u65b9\u5f0f\u3002\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u9700\u6c42\u8fdb\u884c\u9009\u62e9\uff1a\n\n- **\u4f7f\u7528\u6a21\u578b\u914d\u7f6e**\uff1a\u8fd9\u662f\u6784\u5efa\u4e0e\u6a21\u578b API \u65e0\u5173\u7684\u5e94\u7528\u7a0b\u5e8f\u7684\u63a8\u8350\u65b9\u5f0f\u3002\u53ef\u4ee5\u901a\u8fc7\u4fee\u6539\u914d\u7f6e\u6765\u66f4\u6539\u6a21\u578b API\uff0c\u800c\u65e0\u9700\u66f4\u6539\u667a\u80fd\u4f53\u4ee3\u7801\u3002\n- **\u663e\u5f0f\u521d\u59cb\u5316\u6a21\u578b**\uff1a\u5982\u679c\u53ea\u60f3\u4f7f\u7528\u7279\u5b9a\u7684\u6a21\u578b API\uff0c\u663e\u5f0f\u521d\u59cb\u5316\u6a21\u578b\u4f1a\u66f4\u52a0\u65b9\u4fbf\u548c\u900f\u660e\u3002API \u6587\u6863\u5b57\u7b26\u4e32\u63d0\u4f9b\u4e86\u53c2\u6570\u548c\u7528\u6cd5\u7684\u8be6\u7ec6\u4fe1\u606f\u3002\n\n.. tip:: \u5b9e\u9645\u4e0a\uff0c\u4f7f\u7528\u914d\u7f6e\u548c\u663e\u5f0f\u521d\u59cb\u5316\u6a21\u578b\u662f\u7b49\u6548\u7684\u3002\u4f7f\u7528\u6a21\u578b\u914d\u7f6e\u65f6\uff0cAgentScope \u53ea\u662f\u5c06\u914d\u7f6e\u4e2d\u7684\u952e\u503c\u5bf9\u4f20\u9012\u7ed9\u6a21\u578b\u7684\u6784\u9020\u51fd\u6570\u3002\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nfrom agentscope.models import (\n    DashScopeChatWrapper,\n    ModelWrapperBase,\n    ModelResponse,\n)\nimport agentscope"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u4f7f\u7528\u914d\u7f6e\n\u5728\u6a21\u578b\u914d\u7f6e\u4e2d\uff0c\u9700\u8981\u63d0\u4f9b\u4ee5\u4e0b\u4e09\u4e2a\u5b57\u6bb5\uff1a\n\n- config_name\uff1a\u914d\u7f6e\u7684\u540d\u79f0\u3002\n- model_type\uff1a\u6a21\u578b API \u7684\u7c7b\u578b\uff0c\u4f8b\u5982 \"dashscope_chat\"\u3001\"openai_chat\" \u7b49\u3002\n- model_name\uff1a\u6a21\u578b\u7684\u540d\u79f0\uff0c\u4f8b\u5982 \"qwen-max\"\u3001\"gpt-4o\" \u7b49\u3002\n\n\u5728\u4f7f\u7528\u6a21\u578b API \u4e4b\u524d\u901a\u8fc7\u8c03\u7528 `agentscope.init()` \u6765\u52a0\u8f7d\u914d\u7f6e\uff0c\u5982\u4e0b\u6240\u793a\uff1a\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "agentscope.init(\n    model_configs=[\n        {\n            \"config_name\": \"gpt-4o_temperature-0.5\",\n            \"model_type\": \"openai_chat\",\n            \"model_name\": \"gpt-4o\",\n            \"api_key\": \"xxx\",\n            \"temperature\": 0.5,\n        },\n        {\n            \"config_name\": \"my-qwen-max\",\n            \"model_type\": \"dashscope_chat\",\n            \"model_name\": \"qwen-max\",\n        },\n    ],\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5bf9\u4e8e\u5176\u5b83\u53ef\u9009\u53c2\u6570\uff0c\u53ef\u4ee5\u67e5\u770b\u5bf9\u5e94\u6a21\u578b API \u7684\u6784\u9020\u51fd\u6570\u7684\u8bf4\u660e\u3002\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u663e\u5f0f\u521d\u59cb\u5316\u6a21\u578b\n`agentscope.models` \u6a21\u5757\u63d0\u4f9b\u4e86\u6240\u6709\u7684\u5185\u7f6e\u6a21\u578b API\u3002\n\u60a8\u53ef\u4ee5\u901a\u8fc7\u8c03\u7528\u76f8\u5e94\u7684\u6a21\u578b\u7c7b\u6765\u663e\u5f0f\u521d\u59cb\u5316\u6a21\u578b\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u6253\u5370 agentscope.models \u4e0b\u7684\u6a21\u5757\nfor module_name in agentscope.models.__all__:\n    if module_name.endswith(\"Wrapper\"):\n        print(module_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4ee5 DashScope Chat API \u4e3a\u4f8b\uff1a\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = DashScopeChatWrapper(\n    config_name=\"_\",\n    model_name=\"qwen-max\",\n    api_key=os.environ[\"DASHSCOPE_API_KEY\"],\n    stream=False,\n)\n\nresponse = model(\n    messages=[\n        {\"role\": \"user\", \"content\": \"\u55e8\uff01\"},\n    ],\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`response` \u662f `agentscope.models.ModelResponse` \u7684\u4e00\u4e2a\u5bf9\u8c61\uff0c\u5b83\u5305\u542b\u4ee5\u4e0b\u5b57\u6bb5\uff1a\n\n- text\uff1a\u751f\u6210\u7684\u6587\u672c\n- embedding\uff1a\u751f\u6210\u7684\u5d4c\u5165\n- image_urls\uff1a\u5f15\u7528\u751f\u6210\u7684\u56fe\u50cf\n- raw\uff1a\u6765\u81ea API \u7684\u539f\u59cb\u54cd\u5e94\n- parsed\uff1a\u89e3\u6790\u540e\u7684\u54cd\u5e94\uff0c\u4f8b\u5982\u5c06\u5b57\u7b26\u4e32\u89e3\u6790\u6210 JSON \u5bf9\u8c61\n- stream\uff1a\u7528\u6765\u6302\u8f7d\u6d41\u5f0f\u54cd\u5e94\u7684\u751f\u6210\u5668\uff0c\u66f4\u591a\u8be6\u60c5\u8bf7\u53c2\u8003 `streaming` \u4e00\u8282\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"\u6587\u672c\uff1a{response.text}\")\nprint(f\"\u5d4c\u5165\uff1a{response.embedding}\")\nprint(f\"\u56fe\u50cfURL\uff1a{response.image_urls}\")\nprint(f\"\u539f\u59cb\u54cd\u5e94\uff1a{response.raw}\")\nprint(f\"\u89e3\u6790\u540e\u54cd\u5e94\uff1a{response.parsed}\")\nprint(f\"\u6d41\u54cd\u5e94\uff1a{response.stream}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n## \u96c6\u6210\u65b0\u7684 LLM API\n\u5c06\u65b0\u7684 LLM API \u96c6\u6210\u5230 AgentScope \u6709\u4e24\u79cd\u65b9\u5f0f\u3002\n\n### OpenAI \u517c\u5bb9 API\n\n\u5982\u679c\u60a8\u7684\u6a21\u578b\u4e0e OpenAI Python API \u517c\u5bb9\uff0c\u5efa\u8bae\u91cd\u7528 `OpenAIChatWrapper` \u7c7b\u5e76\u63d0\u4f9b\u7279\u5b9a\u53c2\u6570\u3002\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>\u9700\u8981\u786e\u4fdd API \u7684\u56de\u590d\u540c\u6837\u517c\u5bb9 OpenAI Python API\u3002</p></div>\n\n\u4ee5 vLLM \u4e3a\u4f8b\uff0c\n\u5176 [\u5b98\u65b9\u6587\u6863](https://github.com/vllm-project/vllm?tab=readme-ov-file) \u63d0\u4f9b\u4e86\u4ee5\u4e0b\u4f7f\u7528 OpenAI Python \u5e93\u7684\u793a\u4f8b\uff1a\n\n```python\nfrom openai import OpenAI\nclient = OpenAI(\n    base_url=\"http://localhost:8000/v1\",\n    api_key=\"token-abc123\",\n)\n\ncompletion = client.chat.completions.create(\n    model=\"NousResearch/Meta-Llama-3-8B-Instruct\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hello!\"}\n    ],\n    temperature=0.5,\n)\n\nprint(completion.choices[0].message)\n```\n\u5c06 vLLM \u96c6\u6210\u5230 AgentScope \u975e\u5e38\u7b80\u5355\uff0c\u5982\u4e0b\uff1a\n\n- \u5c06\u521d\u59cb\u5316 OpenAI \u5ba2\u6237\u7aef\u7684\u53c2\u6570\uff08\u9664\u4e86 `api_key`\uff09\u653e\u5165 `client_args`\uff0c\n- \u5c06\u751f\u6210\u5b8c\u6210\u7684\u53c2\u6570\uff08\u9664\u4e86 `model`\uff09\u653e\u5165 `generate_args`\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vllm_model_config = {\n    \"model_type\": \"openai_chat\",\n    \"config_name\": \"vllm_llama2-7b-chat-hf\",\n    \"model_name\": \"meta-llama/Llama-2-7b-chat-hf\",\n    \"api_key\": \"token-abc123\",  # API \u5bc6\u94a5\n    \"client_args\": {\n        \"base_url\": \"http://localhost:8000/v1/\",  # \u7528\u4e8e\u6307\u5b9a API \u7684\u57fa\u7840 URL\n    },\n    \"generate_args\": {\n        \"temperature\": 0.5,  # \u751f\u6210\u53c2\u6570\uff0c\u5982 temperature\u3001seed\n    },\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6216\u8005\uff0c\u76f4\u63a5\u7528\u53c2\u6570\u521d\u59cb\u5316 OpenAI Chat API \u7684\u6a21\u578b\u7c7b\uff1a\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from agentscope.models import OpenAIChatWrapper\n\nmodel = OpenAIChatWrapper(\n    config_name=\"\",\n    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n    api_key=\"token-abc123\",\n    client_args={\"base_url\": \"http://localhost:8000/v1/\"},\n    generate_args={\"temperature\": 0.5},\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RESTful API\n\n\u5982\u679c\u60a8\u7684\u6a21\u578b\u901a\u8fc7 RESTful post API \u8bbf\u95ee\uff0c\u5e76\u4e14\u54cd\u5e94\u683c\u5f0f\u4e0e OpenAI API \u517c\u5bb9\uff0c\u53ef\u4ee5\u8003\u8651\u4f7f\u7528 `PostAPIChatWrapper`\u3002\n\n\u4ee5\u4e0b\u9762\u7684 curl \u547d\u4ee4\u4e3a\u4f8b\uff0c\u53ea\u9700\u5c06 header\u3001API URL \u548c data\uff08\u9664\u4e86 `messages`\uff0c\u5b83\u5c06\u81ea\u52a8\u4f20\u9012\uff09\u63d0\u53d6\u6210\u6a21\u578b\u7c7b\u7684\u521d\u59cb\u5316\u53c2\u6570\u5373\u53ef\u3002\n\n\u4e00\u4e2a\u793a\u4f8b post \u8bf7\u6c42\uff1a\n\n```bash\ncurl https://api.openai.com/v1/chat/completions\n-H \"Content-Type: application/json\"\n-H \"Authorization: Bearer $OPENAI_API_KEY\"\n-d '{\n        \"model\": \"gpt-4o\",\n        \"messages\": [\n            {\"role\": \"user\", \"content\": \"write a haiku about ai\"}\n        ]\n    }'\n```\n\u76f8\u5e94\u7684\u6a21\u578b\u7c7b\u521d\u59cb\u5316\u5982\u4e0b\uff1a\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from agentscope.models import PostAPIChatWrapper\n\npost_api_model = PostAPIChatWrapper(\n    config_name=\"\",\n    api_url=\"https://api.openai.com/v1/chat/completions\",  # \u76ee\u6807 URL\n    headers={\n        \"Content-Type\": \"application/json\",  # \u6765\u81ea\u5934\u90e8\n        \"Authorization\": \"Bearer $OPENAI_API_KEY\",\n    },\n    json_args={\n        \"model\": \"gpt-4o\",  # \u6765\u81ea\u6570\u636e\n    },\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5b83\u7684\u6a21\u578b\u914d\u7f6e\u5982\u4e0b\uff1a\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "post_api_config = {\n    \"config_name\": \"{my_post_model_config_name}\",\n    \"model_type\": \"post_api_chat\",\n    \"api_url\": \"https://api.openai.com/v1/chat/completions\",\n    \"headers\": {\n        \"Authorization\": \"Bearer {YOUR_API_TOKEN}\",\n    },\n    \"json_args\": {\n        \"model\": \"gpt-4o\",\n    },\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5982\u679c\u4f60\u7684\u6a21\u578b API \u8fd4\u56de\u683c\u5f0f\u4e0e OpenAI \u4e0d\u540c\uff0c\u53ef\u4ee5\u7ee7\u627f `PostAPIChatWrapper` \u5e76\u91cd\u5199 `_parse_response` \u65b9\u6cd5\u3002\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>\u9700\u8981\u5728\u5b50\u7c7b\u4e2d\u5b9a\u4e49\u4e00\u4e2a\u65b0\u7684 `model_type` \u5b57\u6bb5\uff0c\u4ee5\u533a\u5206\u5b83\u4e0e\u73b0\u6709\u7684\u6a21\u578b\u7c7b\u3002</p></div>\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class MyNewModelWrapper(PostAPIChatWrapper):\n    model_type: str = \"{my_new_model_type}\"\n\n    def _parse_response(self, response: dict) -> ModelResponse:\n        \"\"\"\u89e3\u6790\u6765\u81ea API \u670d\u52a1\u5668\u7684\u54cd\u5e94\u3002\n\n        Args:\n            response (`dict`):\n                \u4ece API \u670d\u52a1\u5668\u83b7\u53d6\u7684\u54cd\u5e94\uff0c\u5e76\u901a\u8fc7\n                `response.json()` \u89e3\u6790\u4e3a\u7edf\u4e00\u7684\u683c\u5f0f\u3002\n\n        Returns (`ModelResponse`):\n            \u89e3\u6790\u540e\u7684\u54cd\u5e94\u3002\n        \"\"\"\n        # TODO: \u5c06\u4ee5\u4e0b\u4ee3\u7801\u66ff\u6362\u4e3a\u60a8\u81ea\u5df1\u7684\u89e3\u6790\u903b\u8f91\n        return ModelResponse(\n            text=response[\"data\"][\"response\"][\"choices\"][0][\"message\"][\n                \"content\"\n            ],\n        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \u81ea\u5b9a\u4e49\u6a21\u578b\u7c7b\n\n\u5982\u679c\u9700\u8981\u4ece\u5934\u5f00\u59cb\u5b9e\u73b0\u65b0\u7684\u6a21\u578b\u7c7b\uff0c\u9996\u5148\u9700\u8981\u4e86\u89e3 AgentScope \u4e2d\u7684\u4ee5\u4e0b\u6982\u5ff5\uff1a\n\n- **model_type**\uff1a\u5728\u4f7f\u7528\u6a21\u578b\u914d\u7f6e\u65f6\uff0cAgentScope \u4f7f\u7528 `model_type` \u5b57\u6bb5\u6765\u533a\u5206\u4e0d\u540c\u7684\u6a21\u578b API\u3002\u56e0\u6b64\uff0c\u8bf7\u786e\u4fdd\u60a8\u7684\u65b0\u6a21\u578b\u7c7b\u5177\u6709\u552f\u4e00\u7684 `model_type`\u3002\n- **__init__**\uff1a\u4ece\u6a21\u578b\u914d\u7f6e\u521d\u59cb\u5316\u65f6\uff0cAgentScope \u4f1a\u5c06\u914d\u7f6e\u4e2d\u7684\u6240\u6709\u952e\u503c\u5bf9\u4f20\u9012\u7ed9\u6a21\u578b\u7c7b\u7684 `__init__` \u65b9\u6cd5\u3002\u56e0\u6b64\uff0c\u8bf7\u786e\u4fdd\u60a8\u7684 `__init__` \u65b9\u6cd5\u53ef\u4ee5\u5904\u7406\u914d\u7f6e\u4e2d\u7684\u6240\u6709\u53c2\u6570\u3002\n- **__call__**\uff1a\u6a21\u578b\u7c7b\u7684\u6838\u5fc3\u65b9\u6cd5\u662f `__call__`\uff0c\u5b83\u63a5\u6536\u8f93\u5165\u6d88\u606f\u5e76\u8fd4\u56de\u54cd\u5e94\u3002\u5176\u8fd4\u56de\u503c\u5e94\u8be5\u662f `ModelResponse` \u5bf9\u8c61\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class MyNewModelWrapper(ModelWrapperBase):\n    model_type: str = \"{my_new_model_type}\"\n\n    def __init__(self, config_name, model_name, **kwargs) -> None:\n        super().__init__(config_name, model_name=model_name)\n\n        # TODO: \u5728\u8fd9\u91cc\u521d\u59cb\u5316\u60a8\u7684\u6a21\u578b\n\n    def __call__(self, *args, **kwargs) -> ModelResponse:\n        # TODO: \u5728\u8fd9\u91cc\u5b9e\u73b0\u60a8\u7684\u6a21\u578b\u7684\u6838\u5fc3\u903b\u8f91\n\n        return ModelResponse(\n            text=\"Hello, World!\",\n        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. tip:: \u53ef\u9009\u5730\uff0c\u53ef\u4ee5\u5728\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e00\u4e2a `format` \u65b9\u6cd5\uff0c\u4ece\u800c\u5c06 AgentScope \u4e2d\u7684 `Msg` \u7c7b \u8f6c\u5316\u4e3a\u76ee\u6807\u6a21\u578b API \u8981\u6c42\u7684\u683c\u5f0f\u3002\u66f4\u591a\u8be6\u60c5\u8bf7\u53c2\u8003 `prompt-engineering`\u3002\n\n## \u8fdb\u4e00\u6b65\u9605\u8bfb\n- `prompt-engineering`\n- `streaming`\n- `structured-output`\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}