{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# \u6a21\u578b\n\n\u5728\u672c\u6559\u7a0b\u4e2d\uff0c\u6211\u4eec\u4ecb\u7ecd AgentScope \u4e2d\u96c6\u6210\u7684\u6a21\u578b API\u3001\u5982\u4f55\u4f7f\u7528\u5b83\u4eec\uff0c\u4ee5\u53ca\u5982\u4f55\u96c6\u6210\u65b0\u7684\u6a21\u578b API\u3002\nAgentScope \u76ee\u524d\u652f\u6301\u7684\u6a21\u578b API \u548c\u6a21\u578b\u63d0\u4f9b\u5546\u5305\u62ec\uff1a\n\n.. list-table::\n    :header-rows: 1\n\n    * - API\n      - \u7c7b\n      - \u517c\u5bb9\n      - \u6d41\u5f0f\n      - \u5de5\u5177\n      - \u89c6\u89c9\n      - \u63a8\u7406\n    * - OpenAI\n      - ``OpenAIChatModel``\n      - vLLM, DeepSeek\n      - \u2705\n      - \u2705\n      - \u2705\n      - \u2705\n    * - DashScope\n      - ``DashScopeChatModel``\n      -\n      - \u2705\n      - \u2705\n      - \u2705\n      - \u2705\n    * - Anthropic\n      - ``AnthropicChatModel``\n      -\n      - \u2705\n      - \u2705\n      - \u2705\n      - \u2705\n    * - Gemini\n      - ``GeminiChatModel``\n      -\n      - \u2705\n      - \u2705\n      - \u2705\n      - \u2705\n    * - Ollama\n      - ``OllamaChatModel``\n      -\n      - \u2705\n      - \u2705\n      - \u2705\n      - \u2705\n\n\u4e3a\u4e86\u63d0\u4f9b\u7edf\u4e00\u7684\u6a21\u578b\u63a5\u53e3\uff0c\u4e0a\u8ff0\u6240\u6709\u7c7b\u5747\u88ab\u7edf\u4e00\u4e3a\uff1a\n\n- ``__call__`` \u51fd\u6570\u7684\u524d\u4e09\u4e2a\u53c2\u6570\u662f ``messages``\uff0c``tools`` \u548c ``tool_choice``\uff0c\u5206\u522b\u662f\u8f93\u5165\u6d88\u606f\uff0c\u5de5\u5177\u51fd\u6570\u7684 JSON schema\uff0c\u4ee5\u53ca\u5de5\u5177\u9009\u62e9\u7684\u6a21\u5f0f\u3002\n- \u975e\u6d41\u5f0f\u8fd4\u56de\u65f6\uff0c\u8fd4\u56de\u7c7b\u578b\u662f ``ChatResponse`` \u5b9e\u4f8b\uff1b\u6d41\u5f0f\u8fd4\u56de\u65f6\uff0c\u8fd4\u56de\u7684\u662f ``ChatResponse`` \u7684\u5f02\u6b65\u751f\u6210\u5668\u3002\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>\u4e0d\u540c\u7684\u6a21\u578b API \u5728\u8f93\u5165\u6d88\u606f\u683c\u5f0f\u4e0a\u6709\u6240\u4e0d\u540c\uff0cAgentScope \u901a\u8fc7 formatter \u6a21\u5757\u5904\u7406\u6d88\u606f\u7684\u8f6c\u6362\uff0c\u8bf7\u53c2\u8003 `format`\u3002</p></div>\n\n``ChatResponse`` \u5305\u542b\u5927\u6a21\u578b\u751f\u6210\u7684\u63a8\u7406/\u6587\u672c/\u5de5\u5177\u4f7f\u7528\u5185\u5bb9\u3001\u8eab\u4efd\u3001\u521b\u5efa\u65f6\u95f4\u548c\u4f7f\u7528\u4fe1\u606f\u3002\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import asyncio\nimport json\nimport os\n\nfrom agentscope.message import TextBlock, ToolUseBlock, ThinkingBlock, Msg\nfrom agentscope.model import ChatResponse, DashScopeChatModel\n\nresponse = ChatResponse(\n    content=[\n        ThinkingBlock(\n            type=\"thinking\",\n            thinking=\"\u6211\u5e94\u8be5\u5728 Google \u4e0a\u641c\u7d22 AgentScope\u3002\",\n        ),\n        TextBlock(type=\"text\", text=\"\u6211\u5c06\u5728 Google \u4e0a\u641c\u7d22 AgentScope\u3002\"),\n        ToolUseBlock(\n            type=\"tool_use\",\n            id=\"642n298gjna\",\n            name=\"google_search\",\n            input={\"query\": \"AgentScope\"},\n        ),\n    ],\n)\n\nprint(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4ee5 ``DashScopeChatModel`` \u4e3a\u4f8b\uff0c\u8c03\u7528\u548c\u8fd4\u56de\u7ed3\u679c\u5982\u4e0b\uff1a\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "async def example_model_call() -> None:\n    \"\"\"\u4f7f\u7528 DashScopeChatModel \u7684\u793a\u4f8b\u3002\"\"\"\n    model = DashScopeChatModel(\n        model_name=\"qwen-max\",\n        api_key=os.environ[\"DASHSCOPE_API_KEY\"],\n        stream=False,\n    )\n\n    res = await model(\n        messages=[\n            {\"role\": \"user\", \"content\": \"\u4f60\u597d\uff01\"},\n        ],\n    )\n\n    # \u60a8\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u54cd\u5e94\u5185\u5bb9\u521b\u5efa ``Msg`` \u5bf9\u8c61\n    msg_res = Msg(\"Friday\", res.content, \"assistant\")\n\n    print(\"LLM \u8fd4\u56de\u7ed3\u679c:\", res)\n    print(\"\u4f5c\u4e3a Msg \u7684\u54cd\u5e94:\", msg_res)\n\n\nasyncio.run(example_model_call())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u6d41\u5f0f\u8fd4\u56de\n\u8981\u542f\u7528\u6d41\u5f0f\u8fd4\u56de\uff0c\u8bf7\u5728\u6a21\u578b\u7684\u6784\u9020\u51fd\u6570\u4e2d\u5c06 ``stream`` \u53c2\u6570\u8bbe\u7f6e\u4e3a ``True``\u3002\n\u6d41\u5f0f\u8fd4\u56de\u4e2d\uff0c``__call__`` \u65b9\u6cd5\u5c06\u8fd4\u56de\u4e00\u4e2a **\u5f02\u6b65\u751f\u6210\u5668**\uff0c\u8be5\u751f\u6210\u5668\u8fed\u4ee3\u8fd4\u56de ``ChatResponse`` \u5b9e\u4f8b\u3002\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>AgentScope \u4e2d\u7684\u6d41\u5f0f\u8fd4\u56de\u7ed3\u679c\u4e3a **\u7d2f\u52a0\u5f0f**\uff0c\u8fd9\u610f\u5473\u7740\u6bcf\u4e2a chunk \u4e2d\u7684\u5185\u5bb9\u5305\u542b\u6240\u6709\u4e4b\u524d\u7684\u5185\u5bb9\u52a0\u4e0a\u65b0\u751f\u6210\u7684\u5185\u5bb9\u3002</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "async def example_streaming() -> None:\n    \"\"\"\u4f7f\u7528\u6d41\u5f0f\u6a21\u578b\u7684\u793a\u4f8b\u3002\"\"\"\n    model = DashScopeChatModel(\n        model_name=\"qwen-max\",\n        api_key=os.environ[\"DASHSCOPE_API_KEY\"],\n        stream=True,\n    )\n\n    generator = await model(\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": \"\u4ece 1 \u6570\u5230 20\uff0c\u53ea\u62a5\u544a\u6570\u5b57\uff0c\u4e0d\u8981\u4efb\u4f55\u5176\u4ed6\u4fe1\u606f\u3002\",\n            },\n        ],\n    )\n    print(\"\u54cd\u5e94\u7684\u7c7b\u578b:\", type(generator))\n\n    i = 0\n    async for chunk in generator:\n        print(f\"\u5757 {i}\")\n        print(f\"\\t\u7c7b\u578b: {type(chunk.content)}\")\n        print(f\"\\t{chunk}\\n\")\n        i += 1\n\n\nasyncio.run(example_streaming())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u63a8\u7406\u6a21\u578b\nAgentScope \u901a\u8fc7\u63d0\u4f9b ``ThinkingBlock`` \u6765\u652f\u6301\u63a8\u7406\u6a21\u578b\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "async def example_reasoning() -> None:\n    \"\"\"\u4f7f\u7528\u63a8\u7406\u6a21\u578b\u7684\u793a\u4f8b\u3002\"\"\"\n    model = DashScopeChatModel(\n        model_name=\"qwen-turbo\",\n        api_key=os.environ[\"DASHSCOPE_API_KEY\"],\n        enable_thinking=True,\n    )\n\n    res = await model(\n        messages=[\n            {\"role\": \"user\", \"content\": \"\u6211\u662f\u8c01\uff1f\"},\n        ],\n    )\n\n    last_chunk = None\n    async for chunk in res:\n        last_chunk = chunk\n    print(\"\u6700\u7ec8\u54cd\u5e94:\")\n    print(last_chunk)\n\n\nasyncio.run(example_reasoning())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u5de5\u5177 API\n\u4e0d\u540c\u7684\u6a21\u578b\u63d0\u4f9b\u5546\u5728\u5de5\u5177 API \u65b9\u9762\u6709\u6240\u4e0d\u540c\uff0c\u4f8b\u5982\u5de5\u5177 JSON schema\u3001\u5de5\u5177\u8c03\u7528/\u54cd\u5e94\u683c\u5f0f\u3002\n\u4e3a\u4e86\u63d0\u4f9b\u7edf\u4e00\u7684\u63a5\u53e3\uff0cAgentScope \u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u89e3\u51b3\u4e86\u8fd9\u4e2a\u95ee\u9898\uff1a\n\n- \u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u5de5\u5177\u8c03\u7528\u7ed3\u6784 block `ToolUseBlock <tool-block>` \u548c\u5de5\u5177\u54cd\u5e94\u7ed3\u6784 `ToolResultBlock <tool-block>`\u3002\n- \u5728\u6a21\u578b\u7c7b\u7684 ``__call__`` \u65b9\u6cd5\u4e2d\u63d0\u4f9b\u7edf\u4e00\u7684\u5de5\u5177\u63a5\u53e3 ``tools``\uff0c\u63a5\u53d7\u5de5\u5177 JSON schema \u5217\u8868\uff0c\u5982\u4e0b\u6240\u793a\uff1a\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "json_schemas = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"google_search\",\n            \"description\": \"\u5728 Google \u4e0a\u641c\u7d22\u67e5\u8be2\u3002\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"query\": {\n                        \"type\": \"string\",\n                        \"description\": \"\u641c\u7d22\u67e5\u8be2\u3002\",\n                    },\n                },\n                \"required\": [\"query\"],\n            },\n        },\n    },\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u8fdb\u4e00\u6b65\u9605\u8bfb\n- `message`\n- `prompt`\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}