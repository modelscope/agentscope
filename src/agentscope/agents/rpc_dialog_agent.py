# -*- coding: utf-8 -*-
""" A rpc version of dialog agent."""
import json
from typing import Any
from typing import Callable
from typing import Optional
from typing import Union
from loguru import logger

from agentscope.message import Msg
from agentscope.agents.rpc_agent import RpcAgentBase
from agentscope.prompt import PromptEngine
from agentscope.constants import PromptType


class RpcDialogAgent(RpcAgentBase):
    """DialogAgent class"""

    def __init__(
        self,
        name: str,
        config: Optional[dict] = None,
        sys_prompt: Optional[str] = None,
        model: Optional[Union[Callable[..., Any], str]] = None,
        use_memory: bool = True,
        memory_config: Optional[dict] = None,
        host: str = "localhost",
        port: int = 80,
        max_pool_size: int = 100,
        max_timeout_seconds: int = 1800,
        launch_server: bool = True,
        local_mode: bool = True,
        lazy_launch: bool = True,
        is_servicer: bool = False,
    ) -> None:
        super().__init__(
            name=name,
            config=config,
            sys_prompt=sys_prompt,
            model=model,
            use_memory=use_memory,
            memory_config=memory_config,
            host=host,
            port=port,
            max_pool_size=max_pool_size,
            max_timeout_seconds=max_timeout_seconds,
            launch_server=launch_server,
            local_mode=local_mode,
            lazy_launch=lazy_launch,
            is_servicer=is_servicer,
        )
        # init prompt engine
        if is_servicer:
            self.engine = PromptEngine(self.model, prompt_type=PromptType.LIST)

    def reply(self, x: dict = None) -> dict:
        """Reply function of the agent. Processes the input data,
        generates a prompt using the current dialogue memory and system
        prompt, and invokes the language model to produce a response. The
        response is then formatted and added to the dialogue memory.

        Args:
            x (`dict`, defaults to `None`):
                A dictionary representing the user's input to the agent.
                This input is added to the dialogue memory if provided.
        Returns:
            dict: A dictionary representing the message generated by the agent
                  in response to the user's input. It contains at least a
                  'speak' key with the textual response and may include other
                  keys such as 'agreement' if provided by the language model.
        Raises:
            `json.decoder.JSONDecodeError`:
                If the response from the language model is not valid JSON,
                it defaults to treating the response as plain text.
        """
        # record the input if needed
        if x is not None:
            self.memory.add(x)

        # prepare prompt
        prompt = self.engine.join(
            self.sys_prompt,
            self.memory.get_memory(),
        )

        # call llm
        response = self.model(
            prompt,
            parse_func=json.loads,
            fault_handler=lambda x: {"speak": x},
        )

        logger.debug(json.dumps(response, indent=4))

        if isinstance(response, dict) and "speak" in response:
            msg = Msg(
                name=self.name,
                content=response.get("speak", None) or response,
                **response,
            )
        else:
            msg = Msg(self.name, response)

        logger.chat(msg)

        # record to memory
        self.memory.add(msg)

        return msg
