{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Build Agent\n\nAgentScope supports to build LLM-empowered agents by providing a basic agent\nclass `agentscope.agents.AgentBase`.\n\nIn the following, we will build a simple dialog agent that can interact with\nthe others.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from agentscope.agents import AgentBase\nfrom agentscope.memory import TemporaryMemory\nfrom agentscope.message import Msg\nfrom agentscope.models import DashScopeChatWrapper\nimport json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the Agent\nWe define a `DialogAgent` class by inheriting from\n`agentscope.agents.AgentBase`, and implement the constructor and\n`reply` methods to make the agent work.\n\nWithin the constructor, we initialize the agent with its name, system prompt,\nmemory, and model.\nIn this example, we take `qwen-max` in DashScope Chat API for model serving.\nYou can replace it with other model wrappers under `agentscope.models`.\n\nThe `reply` method is the core of the agent, which takes message(s) as input\nand returns a reply message.\nWithin the method, we implement the basic logic of the agent:\n- record the input message in memory,\n- construct the prompt with system prompt and memory,\n- call the model to get the response,\n- record the response in memory and return it.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class JarvisAgent(AgentBase):\n    def __init__(self):\n        super().__init__(\"Jarvis\")\n\n        self.name = \"Jarvis\"\n        self.sys_prompt = \"You're a helpful assistant named Jarvis.\"\n        self.memory = TemporaryMemory()\n        self.model = DashScopeChatWrapper(\n            config_name=\"_\",\n            model_name=\"qwen-max\",\n        )\n\n    def reply(self, msg):\n        # Record the message in memory\n        self.memory.add(msg)\n\n        # Construct the prompt with system prompt and memory\n        prompt = self.model.format(\n            Msg(\n                name=\"system\",\n                content=self.sys_prompt,\n                role=\"system\",\n            ),\n            self.memory.get_memory(),\n        )\n\n        # Call the model to get the response\n        response = self.model(prompt)\n\n        # Record the response in memory and return it\n        msg = Msg(\n            name=self.name,\n            content=response.text,\n            role=\"assistant\",\n        )\n        self.memory.add(msg)\n\n        self.speak(msg)\n        return msg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After creating the agent class, we can instantiate it and interact with it\nby sending messages.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "jarvis = JarvisAgent()\n\nmsg = Msg(\n    name=\"user\",\n    content=\"Hi! Jarvis.\",\n    role=\"user\",\n)\n\nmsg_reply = jarvis(msg)\n\nprint(f\"The sender name of the replied message: {msg_reply.name}\")\nprint(f\"The role of the sender: {msg_reply.role}\")\nprint(f\"The content of the replied message: {msg_reply.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "======================\n\n## Components\nNow we briefly introduce the basic components of the above agent, including\n\n* memory\n* model\n\n### Memory\nThe [memory module](#memory) provides basic operations for memory\nmanagement, including adding, deleting and getting memory.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "memory = TemporaryMemory()\n# Add a message\nmemory.add(Msg(\"system\", \"You're a helpful assistant named Jarvis.\", \"system\"))\n# Add multiple messages at once\nmemory.add(\n    [\n        Msg(\"Stank\", \"Hi!\", \"user\"),\n        Msg(\"Jarvis\", \"How can I help you?\", \"assistant\"),\n    ],\n)\nprint(f\"The current memory: {memory.get_memory()}\")\nprint(f\"The current size: {memory.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtain the last two messages with parameter `recent_n`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "recent_two_msgs = memory.get_memory(recent_n=2)\nfor i, msg in enumerate(recent_two_msgs):\n    print(\n        f\"MSG{i}: Sender: {msg.name}, Role: {msg.role}, Content: {msg.content}\",\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Delete the first message within the memory.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "memory.delete(0)\nprint(f\"The memory after deletion: {memory.get_memory()}\")\nprint(f\"The size after deletion: {memory.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model\nThe `agentscope.models` module encapsulates different model API, and\nprovides basic prompt engineering strategies for different APIs in their\n`format` function.\n\nTake DashScope Chat API as an example:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "messages = [\n    Msg(\"system\", \"You're a helpful assistant named Jarvis.\", \"system\"),\n    Msg(\"Stank\", \"Hi!\", \"user\"),\n    Msg(\"Jarvis\", \"How can I help you?\", \"assistant\"),\n]\n\nmodel = DashScopeChatWrapper(\n    config_name=\"api\",\n    model_name=\"qwen-max\",\n)\nprompt = model.format(messages)\nprint(json.dumps(prompt, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Further Reading\n- `builtin_agent`\n- `model_api`\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}