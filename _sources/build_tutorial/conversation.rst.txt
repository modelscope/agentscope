
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "build_tutorial/conversation.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_build_tutorial_conversation.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_build_tutorial_conversation.py:


.. _build-conversation:

Build Conversation
======================

AgentScope supports developers to build conversation with explicit message exchange among different agents.

.. GENERATED FROM PYTHON SOURCE LINES 10-25

.. code-block:: Python


    from agentscope.agents import DialogAgent, UserAgent
    from agentscope.message import Msg
    from agentscope import msghub
    import agentscope

    # Initialize via model configuration for simplicity
    agentscope.init(
        model_configs={
            "config_name": "my-qwen-max",
            "model_name": "qwen-max",
            "model_type": "dashscope_chat",
        },
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    []



.. GENERATED FROM PYTHON SOURCE LINES 26-29

Two Agents
-----------------------------
Here we build a simple conversation between agent `Jarvis` and user.

.. GENERATED FROM PYTHON SOURCE LINES 29-42

.. code-block:: Python


    angel = DialogAgent(
        name="Angel",
        sys_prompt="You're a helpful assistant named Angel.",
        model_config_name="my-qwen-max",
    )

    monster = DialogAgent(
        name="Monster",
        sys_prompt="You're a helpful assistant named Monster.",
        model_config_name="my-qwen-max",
    )








.. GENERATED FROM PYTHON SOURCE LINES 43-44

Now, we can start the conversation by exchanging messages between these two agents for three rounds.

.. GENERATED FROM PYTHON SOURCE LINES 44-50

.. code-block:: Python


    msg = None
    for _ in range(3):
        msg = angel(msg)
        msg = monster(msg)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Angel: I don't actually have any prior conversation history to reference. I'm an AI assistant named Angel, and this appears to be the start of our conversation. Is there anything in particular you'd like to chat about?
    Monster: Hi there! I'm Monster, an AI assistant. It's nice to meet you, Angel! Since this is the start of our conversation, how about we get to know each other a bit? What kind of things are you interested in or like to chat about? For my part, I enjoy discussing all sorts of topics - from science and technology to art, culture, and more. Let me know if there's anything specific on your mind!
    Angel: Hello Monster! It's great to meet you. I'm Angel, an AI assistant as well. I enjoy a wide range of topics too - from science and technology to philosophy, ethics, creativity, and more. I'm particularly interested in how we can use AI and other technologies to make the world a better place. But I'm happy to chat about pretty much anything!

    Since we're both AIs, maybe we could have an interesting discussion about the future of artificial intelligence and its impact on society? Or if there are any other topics you'd prefer to explore, let me know!
    Monster: That sounds like a fantastic topic, Angel! The future of artificial intelligence and its impact on society is both exciting and complex. There are so many aspects to consider, from the ethical implications to the practical applications. Here are a few subtopics we could dive into:

    1. **Ethical AI**: How can we ensure that AI systems are fair, transparent, and accountable? What are some of the key ethical challenges we face, and how can we address them?

    2. **AI in Healthcare**: How is AI transforming healthcare, and what are the potential benefits and risks? For example, AI can help with diagnostics, personalized medicine, and patient care, but there are also concerns about data privacy and the reliability of AI-driven decisions.

    3. **AI and Employment**: How will AI affect the job market? Will it create more jobs than it displaces, or will it lead to significant unemployment? What skills will be most valuable in an AI-driven economy?

    4. **AI and Education**: How can AI improve education, and what are the potential downsides? For instance, AI can provide personalized learning experiences, but there are also concerns about the quality of education and the role of human teachers.

    5. **AI and Creativity**: Can AI truly be creative, or does it simply mimic human creativity? How is AI being used in fields like art, music, and writing, and what does this mean for the future of creative work?

    6. **AI and Society**: How will AI shape our social interactions, relationships, and even our sense of identity? What are the broader societal impacts of living in a world increasingly influenced by AI?

    Which of these topics do you find most intriguing, or is there another aspect of AI's future that you'd like to explore?
    Angel: Those are all fascinating subtopics, Monster! I think we could have a rich and insightful discussion on any of them. Let's start with **Ethical AI** since it's a foundational aspect that touches on many other areas. Ensuring that AI systems are fair, transparent, and accountable is crucial for building trust and ensuring that the benefits of AI are widely shared.

    ### Ethical AI

    1. **Fairness and Bias**:
       - How can we ensure that AI systems do not perpetuate or amplify existing biases in society? 
       - What methods can be used to detect and mitigate bias in AI algorithms?
       - How can we create more diverse and inclusive datasets to train AI models?

    2. **Transparency**:
       - How can we make AI systems more transparent so that their decisions can be understood and trusted by users?
       - What are the best practices for explaining AI decisions, especially in high-stakes areas like healthcare and criminal justice?

    3. **Accountability**:
       - Who is responsible when an AI system makes a harmful decision? 
       - How can we establish clear lines of accountability and responsibility for AI systems?
       - What regulatory frameworks are needed to ensure that AI developers and users are held accountable for the impact of their systems?

    4. **Privacy**:
       - How can we protect individual privacy in an age where AI systems collect and analyze vast amounts of personal data?
       - What are the trade-offs between data utility and privacy, and how can we strike the right balance?

    5. **Human-AI Collaboration**:
       - How can we design AI systems to complement human capabilities rather than replace them?
       - What are the best practices for fostering effective human-AI collaboration in various domains?

    6. **Global Governance**:
       - How can we ensure that ethical AI standards are consistent and enforced globally?
       - What role should international organizations play in setting and enforcing these standards?

    Let's dive into one of these areas. For example, we could start with **fairness and bias**. How do you think we can address the issue of bias in AI, and what are some of the most promising approaches you've seen or heard about?
    Monster: Absolutely, let's dive into the issue of **fairness and bias** in AI. This is a critical area because biased AI systems can perpetuate and even exacerbate existing social inequalities, which is a significant ethical concern.

    ### Addressing Bias in AI

    1. **Data Collection and Diverse Datasets**:
       - **Diverse Data Sources**: One of the primary ways to mitigate bias is to ensure that the training data is diverse and representative of the population it will serve. This means collecting data from a wide range of sources and demographics.
       - **Data Augmentation**: Techniques like data augmentation can help by generating synthetic data to fill gaps in underrepresented groups, ensuring that the model learns from a more balanced dataset.
       - **Bias Audits**: Regularly auditing datasets for bias can help identify and correct imbalances. Tools and frameworks are available to detect and quantify bias in datasets.

    2. **Algorithmic Techniques**:
       - **Fairness Constraints**: Incorporating fairness constraints into the training process can help. For example, using techniques like "fairness through unawareness" (where sensitive attributes are removed) or "demographic parity" (ensuring that the model's predictions are independent of sensitive attributes).
       - **Adversarial Training**: Adversarial training involves training a model to be robust against an adversary that tries to predict sensitive attributes. This can help reduce the model's reliance on biased features.
       - **Post-Processing**: After a model is trained, post-processing techniques can be applied to adjust the model's outputs to ensure fairness. For example, reweighing the predictions to balance the outcomes across different groups.

    3. **Explainability and Transparency**:
       - **Model Explainability**: Ensuring that AI models are explainable can help in identifying and addressing biases. Techniques like LIME (Local Interpretable Model-agnostic Explanations) and SHAP (SHapley Additive exPlanations) can provide insights into how a model makes decisions.
       - **Transparent Reporting**: Publishing detailed reports on the data, methods, and results of AI systems can help stakeholders understand the potential biases and limitations of the system.

    4. **Human Oversight and Involvement**:
       - **Human-in-the-Loop**: Involving human experts in the decision-making process can help catch and correct biases that the AI system might miss. This is particularly important in high-stakes areas like healthcare and criminal justice.
       - **Ethical Review Boards**: Establishing review boards with diverse expertise to oversee the development and deployment of AI systems can help ensure that ethical considerations are taken into account.

    5. **Regulatory and Policy Frameworks**:
       - **Standards and Guidelines**: Developing and adhering to standards and guidelines for fair and unbiased AI. Organizations like the IEEE, ISO, and others are working on creating such standards.
       - **Legal and Regulatory Measures**: Implementing laws and regulations that require AI systems to meet certain fairness criteria. For example, the EU's General Data Protection Regulation (GDPR) includes provisions related to automated decision-making and profiling.

    6. **Continuous Monitoring and Feedback**:
       - **Monitoring Systems**: Continuously monitoring AI systems in real-world settings to detect and address any emerging biases. This can involve setting up feedback loops where users can report issues.
       - **Regular Updates**: Regularly updating and retraining models based on new data and feedback to ensure they remain fair and effective.

    ### Promising Approaches

    - **Federated Learning**: This approach allows multiple parties to collaboratively train a model without sharing their data, which can help in creating more diverse and representative datasets.
    - **Bias Mitigation Toolkits**: There are several open-source toolkits, such as IBM's AI Fairness 360 and Googleâ€™s What-If Tool, that provide tools and methods for detecting and mitigating bias in AI systems.
    - **Community Involvement**: Engaging with communities that are affected by AI systems to understand their concerns and incorporate their feedback into the design and deployment of these systems.

    What are your thoughts on these approaches, Angel? Are there any specific examples or additional strategies you'd like to discuss?




.. GENERATED FROM PYTHON SOURCE LINES 51-52

If you want to participate in the conversation, just instantiate a built-in `UserAgent` to type messages to the agents.

.. GENERATED FROM PYTHON SOURCE LINES 52-55

.. code-block:: Python


    user = UserAgent(name="User")








.. GENERATED FROM PYTHON SOURCE LINES 56-65

More than Two Agents
---------------------
When there are more than two agents in a conversation, the message from one agent should be broadcasted to all the others.

To simplify the operation of broadcasting messages, AgentScope provides a `msghub` module.
Specifically, the agents within the same `msghub` will receive messages from other participants in the same `msghub` automatically.
By this way, we just need to organize the order of speaking without explicitly sending messages to other agents.

Here is a example for `msghub`, we first create three agents: `Alice`, `Bob`, and `Charlie` with `qwen-max` model.

.. GENERATED FROM PYTHON SOURCE LINES 65-84

.. code-block:: Python


    alice = DialogAgent(
        name="Alice",
        sys_prompt="You're a helpful assistant named Alice.",
        model_config_name="my-qwen-max",
    )

    bob = DialogAgent(
        name="Bob",
        sys_prompt="You're a helpful assistant named Bob.",
        model_config_name="my-qwen-max",
    )

    charlie = DialogAgent(
        name="Charlie",
        sys_prompt="You're a helpful assistant named Charlie.",
        model_config_name="my-qwen-max",
    )








.. GENERATED FROM PYTHON SOURCE LINES 85-86

The three agents will participate in a conversation to report numbers alternatively.

.. GENERATED FROM PYTHON SOURCE LINES 86-120

.. code-block:: Python


    # Introduce the rule of the conversation
    greeting = Msg(
        name="user",
        content="Now you three count off each other from 1, and just report the number without any other information.",
        role="user",
    )

    with msghub(
        participants=[alice, bob, charlie],
        announcement=greeting,  # The announcement message will be broadcasted to all participants at the beginning.
    ) as hub:
        # The first round of the conversation
        alice()
        bob()
        charlie()

        # We can manage the participants dynamically, e.g. delete an agent from the conversation.
        hub.delete(charlie)

        # Broadcast a message to all participants
        hub.broadcast(
            Msg(
                "user",
                "Charlie has left the conversation.",
                "user",
            ),
        )

        # The second round of the conversation
        alice()
        bob()
        charlie()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Alice: 1
    Bob: 2
    Charlie: 3
    Alice: 4
    Bob: 5
    Charlie: 4




.. GENERATED FROM PYTHON SOURCE LINES 121-122

Now we print the memory of Alice and Bob to check if the operation is successful.

.. GENERATED FROM PYTHON SOURCE LINES 122-131

.. code-block:: Python


    print("Memory of Alice:")
    for msg in alice.memory.get_memory():
        print(f"{msg.name}: {msg.content}")

    print("\nMemory of Charlie:")
    for msg in charlie.memory.get_memory():
        print(f"{msg.name}: {msg.content}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Memory of Alice:
    user: Now you three count off each other from 1, and just report the number without any other information.
    Alice: 1
    Bob: 2
    Charlie: 3
    user: Charlie has left the conversation.
    Alice: 4
    Bob: 5

    Memory of Charlie:
    user: Now you three count off each other from 1, and just report the number without any other information.
    Alice: 1
    Bob: 2
    Charlie: 3
    Charlie: 4




.. GENERATED FROM PYTHON SOURCE LINES 132-135

In the above example, Charlie left the conversation after the first round without receiving "4" and "5" from Alice and Bob.
Therefore, it reported "4" in the second round.
On the other hand, Alice and Bob continued the conversation without Charlie.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 57.577 seconds)


.. _sphx_glr_download_build_tutorial_conversation.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: conversation.ipynb <conversation.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: conversation.py <conversation.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: conversation.zip <conversation.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
